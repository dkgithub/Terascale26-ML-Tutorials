{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Building Your First Diffusion Model (DDPM)\n",
    "\n",
    "##  Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "-  Understand the forward diffusion process (adding noise)\n",
    "-  Implement a neural network to predict noise\n",
    "-  Train a denoising diffusion probabilistic model\n",
    "-  Generate new samples via reverse diffusion\n",
    "-  Visualize the entire process\n",
    "\n",
    "##  Expected Time: ~25-30 minutes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Background\n",
    "\n",
    "### What is a Diffusion Model?\n",
    "\n",
    "A **Denoising Diffusion Probabilistic Model (DDPM)** is a generative model that learns to generate data by reversing a gradual noising process.\n",
    "\n",
    "**Key Idea:**\n",
    "1. **Forward Process**: Gradually add noise to data until it becomes pure Gaussian noise\n",
    "2. **Reverse Process**: Learn to remove noise step-by-step to generate new samples\n",
    "\n",
    "### Mathematical Formulation\n",
    "\n",
    "**Forward Process** (fixed):\n",
    "$$q(x_t | x_0) = \\mathcal{N}(x_t; \\sqrt{\\bar{\\alpha}_t} x_0, (1 - \\bar{\\alpha}_t) I)$$\n",
    "\n",
    "**Reverse Process** (learned):\n",
    "$$p_\\theta(x_{t-1} | x_t) = \\mathcal{N}(x_{t-1}; \\mu_\\theta(x_t, t), \\sigma_t^2 I)$$\n",
    "\n",
    "**Training Objective**:\n",
    "$$\\mathcal{L} = \\mathbb{E}_{t, x_0, \\epsilon} \\left[ \\|\\epsilon - \\epsilon_\\theta(x_t, t)\\|^2 \\right]$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tutorial modules\n",
    "from ddpm_tutorial.models import SimpleMLPDenoiser\n",
    "from ddpm_tutorial.diffusion import GaussianDiffusion\n",
    "from ddpm_tutorial.utils import (\n",
    "    create_toy_dataset,\n",
    "    ToyDataLoader,\n",
    "    set_seed,\n",
    "    count_parameters,\n",
    "    get_device,\n",
    ")\n",
    "from ddpm_tutorial.visualization import (\n",
    "    visualize_forward_process,\n",
    "    visualize_samples,\n",
    "    plot_training_curves,\n",
    "    visualize_reverse_process_trajectory,\n",
    "    create_reverse_process_animation,\n",
    "    visualize_noise_schedule,\n",
    "    create_summary_figure,\n",
    "    visualize_marginal_distributions,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "set_seed(42)\n",
    "\n",
    "# Get device\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "print(\"Created outputs/ directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Create a 2D Toy Dataset\n",
    "\n",
    "We'll use a 2D dataset so we can easily visualize what's happening!\n",
    "\n",
    "**Available datasets:**\n",
    "- `\"moons\"`: Two interleaving half-circles\n",
    "- `\"circles\"`: Two concentric circles\n",
    "- `\"swiss_roll\"`: Classic swiss roll pattern\n",
    "- `\"two_gaussians\"`: Two separated Gaussian blobs\n",
    "- `\"checkerboard\"`: Challenging checkerboard pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATASET_TYPE = \"moons\"  # Change this to try different datasets!\n",
    "N_SAMPLES = 10000\n",
    "NOISE = 0.05\n",
    "\n",
    "# Create dataset\n",
    "data = create_toy_dataset(\n",
    "    dataset_type=DATASET_TYPE,\n",
    "    n_samples=N_SAMPLES,\n",
    "    noise=NOISE,\n",
    ")\n",
    "\n",
    "print(f\"Created '{DATASET_TYPE}' dataset\")\n",
    "print(f\"  Shape: {data.shape}\")\n",
    "print(f\"  Mean: [{data.mean(0)[0]:.3f}, {data.mean(0)[1]:.3f}]\")\n",
    "print(f\"  Std:  [{data.std(0)[0]:.3f}, {data.std(0)[1]:.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the dataset\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(data[:, 0], data[:, 1], alpha=0.5, s=10)\n",
    "plt.xlim(-3, 3)\n",
    "plt.ylim(-3, 3)\n",
    "plt.xlabel('$x_1$', fontsize=14)\n",
    "plt.ylabel('$x_2$', fontsize=14)\n",
    "plt.title(f'Original Data: {DATASET_TYPE}', fontsize=16)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Question 1\n",
    "\n",
    "**Why do we use 2D toy datasets for this tutorial?**\n",
    "\n",
    "<details>\n",
    "<summary>Click for answer</summary>\n",
    "\n",
    "2D datasets allow us to:\n",
    "1. **Visualize** the entire process easily\n",
    "2. **Train quickly** on limited hardware\n",
    "3. **Understand** what's happening at each step\n",
    "4. **Debug** when things go wrong\n",
    "\n",
    "The same principles apply to high-dimensional data (images, audio, etc.)!\n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Initialize the Diffusion Process\n",
    "\n",
    "The diffusion process defines how we add noise over time.\n",
    "\n",
    "**Key parameters:**\n",
    "- `n_steps`: Number of diffusion timesteps $T$ (typically 100-1000)\n",
    "- `beta_start`, `beta_end`: Controls noise schedule $\\beta_t$\n",
    "- `schedule`: Shape of noise schedule (\"linear\" or \"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diffusion configuration\n",
    "N_STEPS = 100\n",
    "BETA_START = 1e-4\n",
    "BETA_END = 0.02\n",
    "SCHEDULE = \"linear\"  # Try \"cosine\" too!\n",
    "\n",
    "# Create diffusion process\n",
    "diffusion = GaussianDiffusion(\n",
    "    n_steps=N_STEPS,\n",
    "    beta_start=BETA_START,\n",
    "    beta_end=BETA_END,\n",
    "    schedule=SCHEDULE,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(f\"Created Gaussian Diffusion with {N_STEPS} steps\")\n",
    "print(f\"  Noise schedule: {SCHEDULE}\")\n",
    "print(f\"  \u03b2 range: [{BETA_START}, {BETA_END}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the noise schedule\n",
    "visualize_noise_schedule(diffusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Understanding the Noise Schedule\n",
    "\n",
    "- **$\\beta_t$**: Variance added at each step (increases over time)\n",
    "- **$\\alpha_t = 1 - \\beta_t$**: Signal retention (decreases over time)\n",
    "- **$\\bar{\\alpha}_t = \\prod_{s=1}^t \\alpha_s$**: Cumulative signal (approaches 0)\n",
    "\n",
    "At $t = T$, almost all signal is lost and we have pure noise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize forward diffusion: Clean data \u2192 Noise\n",
    "visualize_forward_process(\n",
    "    diffusion,\n",
    "    data[:1000],\n",
    "    timesteps=[0, 25, 50, 75, 99]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Question 2\n",
    "\n",
    "**What do you observe as $t$ increases?**\n",
    "\n",
    "<details>\n",
    "<summary>Click for answer</summary>\n",
    "\n",
    "As $t$ increases:\n",
    "1. The data structure gradually **disappears**\n",
    "2. Points spread out to fill a **Gaussian blob**\n",
    "3. At $t = T$, the distribution is approximately **$\\mathcal{N}(0, I)$**\n",
    "\n",
    "This is the **forward process** we will learn to reverse!\n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create the Neural Network\n",
    "\n",
    "We need a network $\\epsilon_\\theta(x_t, t)$ that predicts the noise given:\n",
    "- Current noisy data $x_t$\n",
    "- Current timestep $t$\n",
    "\n",
    "We'll use a simple **Multi-Layer Perceptron (MLP)** with:\n",
    "- Sinusoidal time embeddings\n",
    "- Multiple hidden layers\n",
    "- ReLU activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "HIDDEN_DIM = 128\n",
    "TIME_EMBED_DIM = 32\n",
    "N_LAYERS = 3\n",
    "\n",
    "# Create model\n",
    "model = SimpleMLPDenoiser(\n",
    "    input_dim=2,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    time_embed_dim=TIME_EMBED_DIM,\n",
    "    n_layers=N_LAYERS,\n",
    ").to(device)\n",
    "\n",
    "n_params = count_parameters(model)\n",
    "print(f\"Created SimpleMLPDenoiser\")\n",
    "print(f\"  Hidden dim: {HIDDEN_DIM}\")\n",
    "print(f\"  Time embed dim: {TIME_EMBED_DIM}\")\n",
    "print(f\"  Number of layers: {N_LAYERS}\")\n",
    "print(f\"  Total parameters: {n_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model Architecture\n",
    "\n",
    "```\n",
    "Input: x_t (2D) + t (scalar)\n",
    "  \u2193\n",
    "Time Embedding: t \u2192 embed_t (TIME_EMBED_DIM)\n",
    "  \u2193\n",
    "Concatenate: [x_t, embed_t]\n",
    "  \u2193\n",
    "MLP: Linear \u2192 ReLU \u2192 ... \u2192 Linear\n",
    "  \u2193\n",
    "Output: \u03b5_pred (2D)\n",
    "```\n",
    "\n",
    "The network learns to predict **what noise was added** at each timestep!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5: Train the Model\n",
    "\n",
    "**Training objective:**\n",
    "$$\\mathcal{L} = \\mathbb{E}_{t, x_0, \\epsilon} \\left[ \\|\\epsilon - \\epsilon_\\theta(x_t, t)\\|^2 \\right]$$\n",
    "\n",
    "**Algorithm:**\n",
    "1. Sample clean data $x_0$ from dataset\n",
    "2. Sample random timestep $t \\sim \\text{Uniform}(1, T)$\n",
    "3. Sample noise $\\epsilon \\sim \\mathcal{N}(0, I)$\n",
    "4. Create noisy sample: $x_t = \\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon$\n",
    "5. Predict noise: $\\epsilon_{\\text{pred}} = \\epsilon_\\theta(x_t, t)$\n",
    "6. Compute loss: $\\mathcal{L} = \\|\\epsilon - \\epsilon_{\\text{pred}}\\|^2$\n",
    "7. Update parameters via gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "BATCH_SIZE = 256\n",
    "N_EPOCHS = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "# Create data loader\n",
    "data_loader = ToyDataLoader(data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(f\"Training configuration:\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Number of epochs: {N_EPOCHS}\")\n",
    "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  Batches per epoch: {len(data_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "model.train()\n",
    "losses = []\n",
    "\n",
    "print(\"Starting training...\\n\")\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    epoch_losses = []\n",
    "    \n",
    "    pbar = tqdm(data_loader, desc=f\"Epoch {epoch+1}/{N_EPOCHS}\")\n",
    "    \n",
    "    for batch in pbar:\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = diffusion.training_loss(model, batch)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Record\n",
    "        epoch_losses.append(loss.item())\n",
    "        pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "    \n",
    "    # Average loss\n",
    "    avg_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "    losses.append(avg_loss)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{N_EPOCHS}, Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"\\n Training complete!\")\n",
    "print(f\"Final loss: {losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curve\n",
    "plot_training_curves(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Question 3\n",
    "\n",
    "**What should the loss curve look like?**\n",
    "\n",
    "<details>\n",
    "<summary>Click for answer</summary>\n",
    "\n",
    "A good training curve should:\n",
    "1. **Start high** (random initialization)\n",
    "2. **Decrease steadily** (learning)\n",
    "3. **Plateau** (convergence)\n",
    "\n",
    "If your loss isn't decreasing:\n",
    "- Learning rate might be too low\n",
    "- Model might be too small\n",
    "- Try training for more epochs\n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Generate New Samples!\n",
    "\n",
    "Now for the exciting part - let's generate new samples!\n",
    "\n",
    "**Reverse sampling algorithm:**\n",
    "1. Start with pure noise: $x_T \\sim \\mathcal{N}(0, I)$\n",
    "2. For $t = T, T-1, ..., 1$:\n",
    "   - Predict noise: $\\epsilon_{\\text{pred}} = \\epsilon_\\theta(x_t, t)$\n",
    "   - Compute mean: $\\mu_\\theta(x_t, t)$\n",
    "   - Sample: $x_{t-1} \\sim \\mathcal{N}(\\mu_\\theta, \\sigma_t^2 I)$\n",
    "3. Return $x_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples\n",
    "model.eval()\n",
    "\n",
    "N_SAMPLES_TO_GENERATE = 1000\n",
    "\n",
    "print(f\"Generating {N_SAMPLES_TO_GENERATE} samples...\")\n",
    "\n",
    "# Generate with trajectory (to visualize the process)\n",
    "trajectory = diffusion.sample(\n",
    "    model,\n",
    "    shape=(N_SAMPLES_TO_GENERATE, 2),\n",
    "    return_trajectory=True,\n",
    ")\n",
    "\n",
    "generated_samples = torch.from_numpy(trajectory[-1])\n",
    "\n",
    "print(f\" Generated {len(generated_samples)} samples!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize reverse sampling process\n",
    "visualize_reverse_process_trajectory(trajectory, n_frames_to_show=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Create Animation\n",
    "\n",
    "Let's create an animation showing the full reverse process!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create animation (this may take a moment)\n",
    "create_reverse_process_animation(\n",
    "    trajectory,\n",
    "    save_path=\"outputs/reverse_sampling.gif\",\n",
    "    fps=20,\n",
    ")\n",
    "\n",
    "print(\"Animation saved! Check outputs/reverse_sampling.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 7: Compare Real vs Generated\n",
    "\n",
    "The moment of truth - how good are our generated samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare side by side\n",
    "visualize_samples(\n",
    "    data[:N_SAMPLES_TO_GENERATE],\n",
    "    generated_samples,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D Marginal Distributions\n",
    "\n",
    "Let's look at the 1D projections along each dimension separately.\n",
    "This helps us understand:\n",
    "- How well each dimension is modeled\n",
    "- Whether the model captures the marginal distributions\n",
    "- Quantitative agreement using metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 1D marginal distributions with agreement metrics\n",
    "visualize_marginal_distributions(\n",
    "    data[:N_SAMPLES_TO_GENERATE],\n",
    "    generated_samples,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Metrics\n",
    "\n",
    "**Wasserstein Distance** (Earth Mover's Distance):\n",
    "- Measures the minimum \"work\" needed to transform one distribution into another\n",
    "- Lower is better (0 = perfect match)\n",
    "- Typical good values: < 0.1 for well-trained models\n",
    "\n",
    "**Histogram Overlap** (Intersection):\n",
    "- Measures how much the histograms overlap\n",
    "- Higher is better (1 = perfect overlap)\n",
    "- Typical good values: > 0.8 for well-trained models\n",
    "\n",
    "These metrics give us quantitative measures of how well the model learned each marginal distribution!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Question 4\n",
    "\n",
    "**How can you tell if the model learned the distribution well?**\n",
    "\n",
    "<details>\n",
    "<summary>Click for answer</summary>\n",
    "\n",
    "Good generated samples should:\n",
    "1. **Match the shape** of the real distribution\n",
    "2. **Cover all modes** (e.g., both moons)\n",
    "3. **Have similar density** in all regions\n",
    "4. **Not have obvious artifacts** or clustering\n",
    "\n",
    "If your samples don't match:\n",
    "- Train longer\n",
    "- Use more diffusion steps\n",
    "- Try a larger model\n",
    "- Adjust the noise schedule\n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Create Summary Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive summary\n",
    "create_summary_figure(\n",
    "    data[:N_SAMPLES_TO_GENERATE],\n",
    "    generated_samples,\n",
    "    losses,\n",
    "    diffusion,\n",
    "    save_path=\"outputs/ddpm_summary.png\",\n",
    ")\n",
    "\n",
    "print(\"Summary figure saved to outputs/ddpm_summary.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Congratulations!\n",
    "\n",
    "You've successfully:\n",
    "1.  Implemented a forward diffusion process\n",
    "2.  Trained a neural network to predict noise\n",
    "3.  Generated new samples via reverse diffusion\n",
    "4.  Visualized the entire process\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Experiments to Try\n",
    "\n",
    "Now that you understand the basics, try these experiments:\n",
    "\n",
    "### Experiment 1: Different Datasets\n",
    "Change `DATASET_TYPE` to:\n",
    "- `\"circles\"`\n",
    "- `\"swiss_roll\"`\n",
    "- `\"two_gaussians\"`\n",
    "- `\"checkerboard\"` (challenging!)\n",
    "\n",
    "How does the model perform on each?\n",
    "\n",
    "### Experiment 2: Noise Schedule\n",
    "Try `SCHEDULE = \"cosine\"` instead of `\"linear\"`\n",
    "\n",
    "Does it train faster? Better quality?\n",
    "\n",
    "### Experiment 3: Number of Steps\n",
    "Change `N_STEPS` to:\n",
    "- 50 (faster sampling)\n",
    "- 200 (slower but potentially better)\n",
    "\n",
    "What's the trade-off?\n",
    "\n",
    "### Experiment 4: Model Size\n",
    "Try different:\n",
    "- `HIDDEN_DIM` (64, 128, 256)\n",
    "- `N_LAYERS` (2, 3, 4, 5)\n",
    "\n",
    "Bigger = better quality?\n",
    "\n",
    "### Experiment 5: Training Time\n",
    "- Try `N_EPOCHS = 50` vs `N_EPOCHS = 200`\n",
    "\n",
    "When does it converge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your experiments here!\n",
    "# Copy cells from above and modify parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Key Takeaways\n",
    "\n",
    "1. **Diffusion models** work by reversing a gradual noising process\n",
    "2. The **forward process** is fixed (just add Gaussian noise)\n",
    "3. The **reverse process** is learned (neural network predicts noise)\n",
    "4. **Training** is simple: predict the noise that was added\n",
    "5. **Sampling** is iterative: gradually denoise from pure noise\n",
    "6. **Noise schedules** matter (linear vs. cosine)\n",
    "7. **More steps** = better quality but slower sampling\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Next Steps\n",
    "\n",
    "Ready to learn more?\n",
    "\n",
    "1. **Tutorial 2**: Flow Matching from Scratch\n",
    "   - Learn about continuous normalizing flows\n",
    "   - Understand velocity fields vs. score functions\n",
    "   - Compare with diffusion models\n",
    "\n",
    "2. **Tutorial 3**: Diffusion vs. Flow Matching\n",
    "   - Side-by-side comparison\n",
    "   - Different samplers (DDPM, DDIM, Euler, RK45)\n",
    "   - Performance benchmarking\n",
    "\n",
    "3. **Read the Papers**:\n",
    "   - [Denoising Diffusion Probabilistic Models (DDPM)](https://arxiv.org/abs/2006.11239)\n",
    "   - [Improved DDPM](https://arxiv.org/abs/2102.09672)\n",
    "   - [Score-Based Generative Modeling](https://arxiv.org/abs/2011.13456)\n",
    "\n",
    "4. **Scale Up**:\n",
    "   - Try on image datasets (MNIST, CIFAR-10)\n",
    "   - Implement conditional generation\n",
    "   - Add classifier guidance\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Questions and Answers\n",
    "\n",
    "### Q: Why does training take so long?\n",
    "**A:** The network needs to learn to denoise at ALL timesteps (0 to T). Each batch trains on random timesteps, so it takes many iterations to cover all well.\n",
    "\n",
    "### Q: Can I use this for images?\n",
    "**A:** Yes! The same principles apply. You'd need:\n",
    "- CNN/U-Net architecture instead of MLP\n",
    "- More timesteps (e.g., 1000)\n",
    "- More training time\n",
    "\n",
    "### Q: What's the difference between DDPM and Score Matching?\n",
    "**A:** They're actually equivalent! DDPM predicts noise, score matching predicts the score (gradient of log probability). They're just different parameterizations.\n",
    "\n",
    "### Q: Why add noise in the first place?\n",
    "**A:** It provides a clear path from data to a simple distribution (Gaussian). The model learns to reverse this path, enabling generation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  You Did It!\n",
    "\n",
    "You've completed Tutorial 1: Building Your First Diffusion Model!\n",
    "\n",
    "**What you learned:**\n",
    "- Forward and reverse diffusion processes\n",
    "- Training a noise prediction network\n",
    "- Generating samples from noise\n",
    "- The role of noise schedules\n",
    "\n",
    "**Keep exploring and have fun with generative models! **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}